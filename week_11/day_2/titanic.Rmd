---
title: "Week 11, day 2 - titanic"
output: html_notebook
---

# Data and libraries
```{r}
library(rpart)
library(rpart.plot)
library(tidyverse)
library(ranger)
library(janitor)
library(modelr)
library(caret)


titanic_set <- read_csv('data/titanic_decision_tree_data.csv')

shuffle_index <- sample(1:nrow(titanic_set))

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]
```

# 1. Cleaning
```{r}
titanic_clean <- titanic_set %>% 
  select(-...1, -passenger_id, -name, -ticket, -fare, -cabin) %>% 
  filter(!is.na(survived)) %>% 
  mutate(sex = factor(sex),
         pclass = factor(pclass),
         embarked = factor(embarked),
         survived = factor(survived),
         age_status = factor(if_else(age <= 16, "child", "adult"))) %>% 
  drop_na()
  
```
# 2. Exploration
```{r message=FALSE, warning=FALSE}
titanic_clean %>% 
  GGally::ggpairs()
```

* pclass
* sex
* age_status/age
* embarked?

# 3. Test-train split

```{r}
n_data <- nrow(titanic_clean)

test_index <- sample(1:n_data, size = n_data * 0.2)

titanic_train <- slice(titanic_clean, -test_index)
titanic_test <- slice(titanic_clean, test_index)
```

```{r}
titanic_train %>% 
  tabyl(survived)

titanic_test %>% 
  tabyl(survived)
```
Since there is not a particularly high volume of data, a higher test train splot is liekly preffered, hence 80:20 was chosen here.
The test and train datasets are fairly well balanced.

# 4. Model
```{r}
titanic_tree_1 <- rpart(
  survived ~ .,
  titanic_train,
  method = "class"
)

rpart.plot(
  titanic_tree_1,
  yesno = 2, 
  type = 2,
  fallen.leaves = TRUE, 
  faclen = 6, 
  digits = 2
)
```

# 5. Findings:

* The majority of people did not survive 
  - probability of surviving was 0.41
* The most significant factor affecting survivability was sex
  - for males, the probability of surviving was 0.21
  - for females, the probability of surviving was 0.73
* For males, the most significant factor was age, the key age being 14
  - the probability of surviving if a male was at lease 14 was 0.17
  - if a male was under 14 the number of siblings was a key factor
  - for male children with at least three siblings there was no chance of survival
  - for male children with less than three siblings they were guaranteed to survive
  - i.e. male children with few siblings were much more likely to survive than male adults
* For females, the most significant factor was class
  - first and second class women had a survival probability of 0.93
  - for third class women had a survival probability of 0.46
  - the biggest factor for third class women was age
  - women at least 39 were very unlikely to survive (0.08)
  - females under 5 had a survival prob of 0.77
  - females between 5-11 had a survival prob of 0 (??)
  - females between 12 and 16 has a survival prob of 0.75
  - women between 17 and 39 with children or parents were more likely to survive than those without (0.67 compared to 0.43)
  - i.e. women from a higher class were more likely to survive, age was an important factor for third class women
  
# 6. Test the model

```{r}
titanic_test_pred <- titanic_test %>% 
  add_predictions(titanic_tree_1, type = "class")

titanic_test_pred %>% 
  tabyl(survived, pred)
```
True Positives = 39
True Negatives = 78
False Positives = 7
False Negatives = 18

```{r}
cat("Sensitivity (TPR): ", 39/(39+7), "\nSpecificity (TNR): ", 78/(78+18))
```
Our model has a high sensitivity (85%). This indicates that it is good at correctly identifying those that survived.
It also has a good specificity (81%). This indicates it is good at correctly identifying those that died, but not as well as it can predict those that survived.

# 2. Extension

```{r}
rf_classifier <- ranger(
  formula = survived ~ .,
  data = titanic_train,
  importance = "impurity",
  num.trees = 1000,
  mtry = 2, 
  min.node.size = 5
)

importance(rf_classifier)
```
It identifies sex > age > pclass > sib_sp.... This matches our single tree.

```{r}
titanic_test_pred_rf <- titanic_test %>% 
  mutate(pred = predict(rf_classifier, titanic_test)$predictions)

conf_mat_rf <- titanic_test_pred_rf %>% 
  tabyl(survived, pred)

conf_mat_rf
```

```{r}
control <- trainControl(
  method = "repeatedcv", 
  number = 5, 
  repeats = 10
)

tune_grid <- expand.grid(mtry = 1:6, splitrule = c("gini", "extratrees"),
                         min.node.size = 1:8)

rf_tune <- train(
  survived ~ ., 
  data = titanic_train, 
  method = "ranger",
  metric = "Kappa",
  num.trees = 1000,
  importance = "impurity",
  tuneGrid = tune_grid, 
  trControl = control
)

rf_tune
```

Best model: mtry = 2, splitrule = gini and min.node.size = 8

```{r}
rf_classifier_2 <- ranger(
  formula = survived ~ .,
  data = titanic_train,
  importance = "impurity",
  num.trees = 1000,
  mtry = 2, 
  splitrule = "gini",
  min.node.size = 8
)

importance(rf_classifier_2)
```
Slightly different importances

```{r}
titanic_test_pred_rf_2 <- titanic_test %>% 
  mutate(pred = predict(rf_classifier_2, titanic_test)$predictions)

conf_mat_rf_2 <- titanic_test_pred_rf_2 %>% 
  tabyl(survived, pred)

titanic_test_pred %>% 
  tabyl(survived, pred)
conf_mat_rf
conf_mat_rf_2
```
It is only 1 data point better than our non-optimized forest, and our single tree.
